{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921c2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pranav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3694 - loss: 1.0781\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5221 - loss: 0.9933\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6228 - loss: 0.9164\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.8237\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.6888\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.5397\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9419 - loss: 0.4275\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.3434\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.2760\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.2141\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1907\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1607\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1402\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.1225\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1089\n",
      "Epoch 16/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1016\n",
      "Epoch 17/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1040\n",
      "Epoch 18/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9772 - loss: 0.0907\n",
      "Epoch 19/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0927\n",
      "Epoch 20/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.0924\n",
      "Epoch 21/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0931\n",
      "Epoch 22/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0682\n",
      "Epoch 23/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0720\n",
      "Epoch 24/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0764\n",
      "Epoch 25/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.0828\n",
      "Epoch 26/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0723\n",
      "Epoch 27/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0695\n",
      "Epoch 28/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.0703\n",
      "Epoch 29/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0606\n",
      "Epoch 30/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0521\n",
      "Epoch 31/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0651\n",
      "Epoch 32/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0468\n",
      "Epoch 33/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0574\n",
      "Epoch 34/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0483\n",
      "Epoch 35/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0478\n",
      "Epoch 36/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0499\n",
      "Epoch 37/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0394\n",
      "Epoch 38/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0457\n",
      "Epoch 39/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0416\n",
      "Epoch 40/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0393\n",
      "Epoch 41/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0400\n",
      "Epoch 42/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0353\n",
      "Epoch 43/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0424\n",
      "Epoch 44/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0276\n",
      "Epoch 45/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0460\n",
      "Epoch 46/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0339\n",
      "Epoch 47/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0455\n",
      "Epoch 48/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0394\n",
      "Epoch 49/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0286\n",
      "Epoch 50/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0320\n",
      "\n",
      "Neural Network Training Finished.\n",
      "\n",
      "Evaluating the trained Neural Network on the test set...\n",
      "Test Accuracy: 0.9800\n",
      "\n",
      "Testing the combined system with example inputs:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "Predicted Risk for Speed=120, Weather=1 (Rainy): High\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Predicted Risk for Speed=30, Weather=0 (Clear): Low\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Predicted Risk for Speed=70, Weather=2 (Foggy): Medium\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Neuro-Fuzzy System Example\"\"\"\n",
    "\n",
    "#!pip install scikit-fuzzy # Uncomment and run this line if you don't have scikit-fuzzy installed\n",
    "\n",
    "import numpy as np\n",
    "import random # Although random is imported, np.random is primarily used\n",
    "import matplotlib.pyplot as plt # Imported but not explicitly used in the provided snippets\n",
    "\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Step 1: Fuzzy Logic Setup ---\n",
    "# Define Fuzzy Antecedent (Input) Variables and their Universes of Discourse\n",
    "\n",
    "# Speed: Range from 0 to 150 (e.g., km/h or mph)\n",
    "speed = ctrl.Antecedent(np.arange(0, 151, 1), 'speed')\n",
    "\n",
    "# Weather: Categorical or scaled numerical input (e.g., 0=clear, 1=rainy, 2=foggy)\n",
    "# Using a universe from 0 to 3 for simplicity based on the data generation approach\n",
    "weather = ctrl.Antecedent(np.arange(0, 3, 1), 'weather')\n",
    "\n",
    "# Define Membership Functions for each Antecedent Variable\n",
    "# Membership functions define how crisp input values map to fuzzy sets (e.g., 'slow', 'medium').\n",
    "\n",
    "# Membership functions for speed\n",
    "speed['slow'] = fuzz.trimf(speed.universe, [0, 0, 60])      # Triangular membership function\n",
    "speed['medium'] = fuzz.trimf(speed.universe, [40, 80, 120]) # Triangular\n",
    "speed['fast'] = fuzz.trimf(speed.universe, [100, 150, 150]) # Triangular\n",
    "\n",
    "# Membership functions for weather\n",
    "# These define the degree to which a weather value corresponds to 'clear', 'rainy', or 'foggy'.\n",
    "# Note: The universe is 0-3, but data is generated as 0, 1, 2.\n",
    "# The triangular functions map these crisp values to membership degrees.\n",
    "weather['clear'] = fuzz.trimf(weather.universe, [0, 0, 0.5])   # Peak at 0 (clear)\n",
    "weather['rainy'] = fuzz.trimf(weather.universe, [0.5, 1, 1.5]) # Peak at 1 (rainy)\n",
    "weather['foggy'] = fuzz.trimf(weather.universe, [1.5, 2, 2]) # Peak at 2 (foggy)\n",
    "\n",
    "# Function to fuzzify crisp inputs into membership degrees\n",
    "def fuzzify_inputs(speed_val, weather_val):\n",
    "    \"\"\"\n",
    "    Takes crisp speed and weather values and returns a list of their\n",
    "    membership degrees for each fuzzy set. These serve as fuzzy features.\n",
    "    \"\"\"\n",
    "    # Calculate membership degrees for speed fuzzy sets\n",
    "    speed_lvls = [\n",
    "        fuzz.interp_membership(speed.universe, speed['slow'].mf, speed_val),\n",
    "        fuzz.interp_membership(speed.universe, speed['medium'].mf, speed_val),\n",
    "        fuzz.interp_membership(speed.universe, speed['fast'].mf, speed_val)\n",
    "    ]\n",
    "\n",
    "    # Calculate membership degrees for weather fuzzy sets\n",
    "    weather_lvls = [\n",
    "        fuzz.interp_membership(weather.universe, weather['clear'].mf, weather_val),\n",
    "        fuzz.interp_membership(weather.universe, weather['rainy'].mf, weather_val),\n",
    "        fuzz.interp_membership(weather.universe, weather['foggy'].mf, weather_val)\n",
    "    ]\n",
    "\n",
    "    # Concatenate the membership degrees from both inputs\n",
    "    # This forms a single feature vector (fuzzy features) for the neural network\n",
    "    return speed_lvls + weather_lvls\n",
    "\n",
    "# --- Step 2: Generate Synthetic Dataset ---\n",
    "# Create a dataset to train the neural network.\n",
    "# The inputs are speed and weather. The output (label) is 'Low', 'Medium', or 'High' risk,\n",
    "# determined by a simple rule-based system acting as the ground truth.\n",
    "\n",
    "np.random.seed(0) # Seed for reproducibility\n",
    "X_raw = [] # To store the fuzzy features (inputs for NN)\n",
    "y_raw = [] # To store the crisp risk labels (outputs for NN training)\n",
    "\n",
    "for _ in range(1000): # Generate 1000 data samples\n",
    "    # Generate random crisp inputs for speed and weather\n",
    "    spd = np.random.uniform(0, 150) # Random speed between 0 and 150\n",
    "    wthr = np.random.choice([0, 1, 2]) # Random weather: 0 (clear), 1 (rainy), or 2 (foggy)\n",
    "\n",
    "    # Fuzzify the crisp inputs to get the fuzzy features\n",
    "    fuzzy_features = fuzzify_inputs(spd, wthr)\n",
    "    X_raw.append(fuzzy_features) # Add fuzzy features to input list\n",
    "\n",
    "    # Rule-based label generation (Simulating a simplified expert system or ground truth)\n",
    "    # This defines what the neural network should learn to predict.\n",
    "    if spd > 100 and wthr > 0: # If speed is high AND weather is not clear (rainy or foggy)\n",
    "        y_raw.append('High')\n",
    "    elif spd > 50: # If speed is moderate to high (and not already classified as High)\n",
    "        y_raw.append('Medium')\n",
    "    else: # Otherwise (speed is low or moderate in clear weather)\n",
    "        y_raw.append('Low')\n",
    "\n",
    "# Encode labels: Convert the string labels ('Low', 'Medium', 'High') into numerical format\n",
    "# that the neural network can understand (e.g., 0, 1, 2).\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_raw) # Fit and transform the raw labels\n",
    "\n",
    "# Convert lists to NumPy arrays for use with TensorFlow/Keras and scikit-learn\n",
    "X = np.array(X_raw) # Features for the neural network\n",
    "y = np.array(y_encoded) # Numerical labels for the neural network\n",
    "\n",
    "# --- Step 3: Train Neural Network ---\n",
    "# Use the generated dataset (fuzzy features X and encoded labels y) to train a simple\n",
    "# feedforward neural network. The network learns the mapping from fuzzy input states\n",
    "# to risk categories based on the synthetic ground truth rules.\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# train_test_split shuffles the data and splits it into 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Neural Network Model (Sequential API)\n",
    "# This is a simple feedforward network (Multi-Layer Perceptron - MLP).\n",
    "model = Sequential([\n",
    "    # Input layer and first hidden layer:\n",
    "    # input_dim=6 because fuzzify_inputs returns a list of 6 values (3 for speed, 3 for weather).\n",
    "    # Dense is a fully connected layer. 12 is the number of neurons in this layer.\n",
    "    # 'relu' (Rectified Linear Unit) is a common activation function.\n",
    "    Dense(12, input_dim=6, activation='relu'),\n",
    "\n",
    "    # Second hidden layer: 8 neurons with 'relu' activation.\n",
    "    Dense(8, activation='relu'),\n",
    "\n",
    "    # Output layer:\n",
    "    # 3 neurons, corresponding to the 3 risk classes ('Low', 'Medium', 'High').\n",
    "    # 'softmax' activation outputs a probability distribution over the classes,\n",
    "    # summing to 1. The class with the highest probability is the predicted class.\n",
    "    Dense(3, activation='softmax') # 3 classes: Low, Medium, High\n",
    "])\n",
    "\n",
    "# Compile the Model: Configure the model for training\n",
    "# loss='sparse_categorical_crossentropy': Suitable for multi-class classification with integer labels.\n",
    "# optimizer='adam': A popular and effective optimization algorithm.\n",
    "# metrics=['accuracy']: Monitor the accuracy during training.\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model: Fit the model to the training data\n",
    "# epochs=50: The number of times the entire training dataset is passed forward and backward through the network.\n",
    "# batch_size=16: The number of samples per gradient update.\n",
    "# verbose=1: Display training progress.\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "print(\"\\nNeural Network Training Finished.\")\n",
    "\n",
    "# --- Step 4: Evaluate Neural Network ---\n",
    "# Assess the performance of the trained network on the unseen test data.\n",
    "print(\"\\nEvaluating the trained Neural Network on the test set...\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0) # verbose=0 hides progress bar\n",
    "\n",
    "# Print the evaluation result\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# --- Example Prediction using the combined system ---\n",
    "# This function demonstrates how a real-world input (crisp speed and weather)\n",
    "# goes through the fuzzy logic part (fuzzification) and then the neural network\n",
    "# for final classification.\n",
    "def predict_risk(speed_input, weather_input):\n",
    "    \"\"\"\n",
    "    Predicts the risk level for given crisp speed and weather inputs\n",
    "    using the combined Fuzzy Logic and Neural Network system.\n",
    "    \"\"\"\n",
    "    # 1. Fuzzify the crisp inputs to get fuzzy features\n",
    "    fuzzy_input = np.array(fuzzify_inputs(speed_input, weather_input)).reshape(1, -1)\n",
    "    # .reshape(1, -1) ensures the input is in the correct shape (1 sample, 6 features)\n",
    "    # expected by the neural network.\n",
    "\n",
    "    # 2. Feed the fuzzy features into the trained Neural Network for prediction\n",
    "    prediction = model.predict(fuzzy_input)\n",
    "\n",
    "    # 3. Get the predicted class index (the one with the highest probability)\n",
    "    predicted_class_index = np.argmax(prediction)\n",
    "\n",
    "    # 4. Convert the predicted class index back to the original string label\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "# --- Try predicting with example inputs ---\n",
    "print(\"\\nTesting the combined system with example inputs:\")\n",
    "# Example 1: Fast speed (120) and Rainy weather (1)\n",
    "predicted_risk_1 = predict_risk(120, 1)\n",
    "print(f\"Predicted Risk for Speed=120, Weather=1 (Rainy): {predicted_risk_1}\") # Expected: High\n",
    "\n",
    "# Example 2: Slow speed (30) and Clear weather (0)\n",
    "predicted_risk_2 = predict_risk(30, 0)\n",
    "print(f\"Predicted Risk for Speed=30, Weather=0 (Clear): {predicted_risk_2}\") # Expected: Low\n",
    "\n",
    "# Example 3: Moderate speed (70) and Foggy weather (2)\n",
    "predicted_risk_3 = predict_risk(70, 2)\n",
    "print(f\"Predicted Risk for Speed=70, Weather=2 (Foggy): {predicted_risk_3}\") # Expected: Medium or High depending on exact position in fuzzy sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aafe90a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pranav\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pranav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
